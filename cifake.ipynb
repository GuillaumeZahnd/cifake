{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4b5f5a-2206-4a4e-86c4-c6f22ec5eef6",
   "metadata": {},
   "source": [
    "# Main Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e74fa-e6ce-44b3-a5df-271878875ed9",
   "metadata": {},
   "source": [
    "Lorem ipsum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4a7b5-bb9e-45f5-b91d-3b5d480f7c68",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d4e68118-b360-4cd2-8ec9-93439c61ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib import image as img\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5692a1df-51b2-4383-8d0e-a41358461f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impose a seed for reproducibility\n",
    "random_seed = 421\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ebcff-4cc7-4601-9d80-2b7d0d13fc3c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7c540-f09a-4380-a07f-d3225e880c07",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "Lorem ipsum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ce36d-0cfc-4c90-be14-fdf48634c0f7",
   "metadata": {},
   "source": [
    "## Credits:\n",
    "\n",
    "> Krizhevsky, A., & Hinton, G. (2009). Learning multiple layers of features from tiny images.\n",
    "\n",
    "> Bird, J.J. and Lotfi, A. (2024). CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fba5b0-143a-410c-9c8c-84f34846c835",
   "metadata": {},
   "source": [
    "## Link to download the dataset\n",
    "\n",
    "[https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images](https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a136fb89-8717-4c0d-b710-625eacc76fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the local path\n",
    "path_dataset = '/media/guillaume/DATA/COMPUTER_VISION_DATASETS/CIFAKE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c4eaa47-2fe7-4cfe-b936-c6725d3d6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive the train/test and real/fake paths\n",
    "path_dataset_train_real = os.path.join(path_dataset, 'train', 'REAL')\n",
    "path_dataset_train_fake = os.path.join(path_dataset, 'train', 'FAKE')\n",
    "path_dataset_test_real = os.path.join(path_dataset, 'test', 'REAL')\n",
    "path_dataset_test_fake = os.path.join(path_dataset, 'test', 'FAKE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1524915-7e89-48bb-b065-c8de82dc469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the samples\n",
    "samples_list_train_real = list(glob.glob(os.path.join(path_dataset_train_real, '*.jpg')))\n",
    "samples_list_test_real = glob.glob(os.path.join(path_dataset_test_real, '*.jpg'))\n",
    "samples_list_train_fake = glob.glob(os.path.join(path_dataset_train_fake, '*.jpg'))\n",
    "samples_list_test_fake = glob.glob(os.path.join(path_dataset_test_fake, '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d90ce88-161d-4c69-9f6e-11d4371c2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "Train split \t Real images: \t 50000\n",
      "Test split \t Real images: \t 10000\n",
      "Train split \t Fake images: \t 50000\n",
      "Test split \t Fake images: \t 10000\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples and ensure the distribution is balanced\n",
    "print('Number of samples:')\n",
    "print('Train split \\t Real images: \\t {}'.format(len(samples_list_train_real)))\n",
    "print('Test split \\t Real images: \\t {}'.format(len(samples_list_test_real)))\n",
    "print('Train split \\t Fake images: \\t {}'.format(len(samples_list_train_fake)))\n",
    "print('Test split \\t Fake images: \\t {}'.format(len(samples_list_test_fake)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a749e40-b325-455e-8e3d-4ec811caa14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply in-place random shuffling\n",
    "random.shuffle(samples_list_train_real)\n",
    "random.shuffle(samples_list_test_real)\n",
    "random.shuffle(samples_list_train_fake)\n",
    "random.shuffle(samples_list_test_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687263de-d391-4545-bea7-d2b9c0027538",
   "metadata": {},
   "source": [
    "# Display a few images\n",
    "number_of_displayed_samples = 16\n",
    "\n",
    "fig, ax = plt.subplots(4, number_of_displayed_samples)\n",
    "fig.set_dpi(300)\n",
    "fig.set_size_inches(10, 3, forward=True)\n",
    "\n",
    "for index in range(number_of_displayed_samples):\n",
    "\n",
    "    axx = ax[0, index]\n",
    "    fig.sca(axx)\n",
    "    plt.imshow(img.imread(os.path.join(path_dataset_train_real, samples_list_train_real[index])))\n",
    "    plt.ylabel('Train\\nREAL') if index==0 else None\n",
    "\n",
    "    axx = ax[1, index]\n",
    "    fig.sca(axx)\n",
    "    plt.imshow(img.imread(os.path.join(path_dataset_test_real, samples_list_test_real[index])))\n",
    "    plt.ylabel('Test\\nREAL') if index==0 else None\n",
    "\n",
    "    axx = ax[2, index]\n",
    "    fig.sca(axx)\n",
    "    plt.imshow(img.imread(os.path.join(path_dataset_train_fake, samples_list_train_fake[index])))\n",
    "    plt.ylabel('Train\\nFAKE') if index==0 else None\n",
    "\n",
    "    axx = ax[3, index]\n",
    "    fig.sca(axx)\n",
    "    plt.imshow(img.imread(os.path.join(path_dataset_test_fake, samples_list_test_fake[index])))\n",
    "    plt.ylabel('Test\\nFAKE') if index==0 else None\n",
    "\n",
    "[axx.set_xticks([]) for axx in ax.ravel()]\n",
    "[axx.set_yticks([]) for axx in ax.ravel()]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4da7c-4ca6-400e-ab0d-f633f70fe89f",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "90b73d62-df52-4164-a3d9-00edb49b908b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_TakeDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dogs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(samples_list_train_real)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdogs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mtf.keras.utils.image_dataset_from_directory(\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    directory=path_dataset_train_real,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    verbose=True\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_TakeDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "image_height, image_width = 32, 32\n",
    "batch_size = 64\n",
    "\n",
    "# Dataloader for the train split\n",
    "train_dataloader = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_dataset_train,\n",
    "    seed=random_seed,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(image_height, image_width)\n",
    ")\n",
    "\n",
    "# Dataloader for the test split\n",
    "test_dataloader = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_dataset_test,\n",
    "    seed=random_seed,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(image_height, image_width)\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4a534-6dbf-4698-b7d5-b4a93a5cec76",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5c394-e184-480c-81d2-0ed8a0c58993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5cc7af-4a22-4610-8231-5834df3acde4",
   "metadata": {},
   "source": [
    "# Constructive criticisms about the current analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c328f0-90f2-4ce8-b893-1268453ab4c5",
   "metadata": {},
   "source": [
    "# Summary of main findings and takeaways to prepare next steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
